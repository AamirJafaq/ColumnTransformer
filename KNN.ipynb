{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyORUxMi8KPwoZXhjzpGYdR2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AamirJafaq/ColumnTransformer/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "a1IwluprVmfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The K-nearest neighbors (KNN) algorithm is a non-parametric, supervised learning classifier, which uses proximity to make predictions. KNN is among the most popular and straightforward algorithms for both classification and regression tasks in machine learning. It is based on the idea that the observations closest to a given data point are the most \"similar\" observations in a data set."
      ],
      "metadata": {
        "id": "1m-9ATMar-lC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbors is also called as a lazy learner algorithm because it does not learn from the training set immediately instead it stores the entire dataset and only does the calculations when it needs to make a prediction (for classification or regression)."
      ],
      "metadata": {
        "id": "81xtgeJmAX_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Methods for Selecting $k$"
      ],
      "metadata": {
        "id": "vBbxy1esK--E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the k-Nearest Neighbours algorithm $k$ is just a number that tells the algorithm how many nearby points or neighbors to look at when it makes a decision. Choosing the right value of k is tricky because if $k$ is too small it can cause overfitting, and if it’s too large it can cause underfitting. Lower values of $k$ can have high variance, but low bias, and larger values of $k$ may lead to high bias and lower variance. If the data has a lot of noise or outliers, a bigger $k$ usually works better. However, if $k$ is too big, the model becomes too simple and may miss important patterns—this problem is called underfitting. So $k$ should be picked carefully based on the data."
      ],
      "metadata": {
        "id": "K_SsgyIQBKAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **Elbow Method** draw a graph showing the error rate or accuracy for different $k$ values. As $k$ increases the error usually drops at first. But after a certain point error stops decreasing quickly. The spot where the curve bends and looks like an elbow is usually the best value for $k$."
      ],
      "metadata": {
        "id": "TCqoCkyKCoMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To choose the best value of k using **cross-validation**, the dataset is first split into training and validation sets, often using k-fold cross-validation. This means dividing the dataset into $k$ parts. For each value of $k$, the KNN model is trained on the training data and evaluated on the validation set. The accuracy or error rate is recorded for every $k$, and the value of $k$ that gives the best performance—meaning the highest accuracy or lowest error—is selected."
      ],
      "metadata": {
        "id": "bN5Ql2IYDa8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance Metrics"
      ],
      "metadata": {
        "id": "G6Cl4cPELRWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In KNN (K-Nearest Neighbors), several distance metrics can be used to measure the similarity between data points, depending on the type of data and problem. The most common distance measures used in KNN are:\n",
        "* Euclidean Distance\n",
        "* Manhattan Distance\n",
        "* Minkowski Distance\n",
        "* Chebyshev Distance\n",
        "* Cosine Similarity/Distance\n",
        "* Hamming Distance"
      ],
      "metadata": {
        "id": "5mtq8LKGEQ2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working of KNN algorithm"
      ],
      "metadata": {
        "id": "HEhxrcQFLYqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thе K-Nearest Neighbors (KNN) algorithm operates on the principle of similarity where it predicts the label or value of a new data point by considering the labels or values of its $k$ nearest neighbors in the training dataset. The main steps involved in the KNN algorithm are:\n",
        "1. Selecting the optimal value of $k$.\n",
        "2. Select a distance metric.\n",
        "3. Find the $k$ nearest neighbors to a new data point.\n",
        "4. For classification, the algorithm assigns the new data point to the class that appears most frequently among the $k$ nearest neighbors, a process known as majority voting. For regression, instead of voting, the algorithm predicts the output value by calculating the average or weighted average of the values of the $k$ nearest neighbors.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CW_DBAgwG0N0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "wN7jHDFnMiyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib as plt"
      ],
      "metadata": {
        "id": "D0RI8bVWMj3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxnrBKyoMwNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}